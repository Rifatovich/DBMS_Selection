# Кейс 1. Супермаркет «Мегамарт»

## Описание задачи

Супермаркет «Мегамарт» планирует разработать систему для кассовых терминалов крупной торговой сети.

**Ключевые требования:**
- мгновенная обработка тысяч мелких транзакций (продажа, возврат) одновременно;
- поддержание целостности данных (остатки на складе не должны уходить в минус);
- строгая консистентность (списанные бонусы должны сразу отражаться в системе лояльности);
- высокая доступность для записи.

---

## Какие ключевые требования к СУБД в этом кейсе?

- **Высокая пропускная способность OLTP** — обработка тысяч одновременных мелких транзакций (продажа, возврат товаров) с минимальной задержкой отклика.
- **ACID-транзакции** — атомарность и консистентность критичны: операция продажи должна включать списание товара со склада, обновление бонусов и фиксацию платежа как единое целое.
- **Строгая консистентность** — изменения (списание бонусов, обновление остатков) должны быть видны сразу после фиксации транзакции во всех подсистемах.
- **Ограничения целостности** — `CHECK` на остатки, foreign keys для связей между таблицами, триггеры для бизнес-правил.
- **Высокая конкурентность** — эффективная обработка параллельных обновлений одних и тех же строк (например, популярные товары) без критической деградации производительности.
- **Высокая доступность для записи** — кассы не должны простаивать при сбоях; требуется репликация и автоматический failover.
- **Масштабируемость** — если сеть растёт географически (филиалы в разных регионах/городах), система должна масштабироваться без переписывания архитектуры.

## Какие компромиссы могут возникнуть?

- **Консистентность vs. латентность** — строгая глобальная консистентность между регионами увеличивает задержку записи (требуется кворум); асинхронная репликация снижает латентность, но создаёт риск несогласованности.
- **Масштабирование vs. сложность** — вертикальное масштабирование (один мощный сервер) проще в эксплуатации, но ограничено железом; горизонтальное (шардинг, распределённые СУБД) даёт рост, но усложняет администрирование.
- **Блокировки vs. throughput** — строгие блокировки (`SELECT FOR UPDATE`) гарантируют целостность при «горячих» строках, но снижают параллелизм; оптимистичные блокировки повышают производительность, но требуют обработки конфликтов и ретраев.
- **TCO vs. функциональность** — managed-решения (Aurora, Spanner) удобны, но дороги и привязывают к вендору; open-source (PostgreSQL, YugabyteDB) дешевле, но требуют собственной экспертизы.
- **Офлайн-режим касс** — если связь нестабильна, обеспечить строгую глобальную консистентность невозможно без очередей и eventual consistency на уровне приложения.

## Какие классы СУБД подходят для решения задачи?

### ✅ Классические реляционные СУБД (RDBMS)
- **Подходят для:** сеть в пределах одного региона/города, централизованная архитектура, нагрузка до 10-20k TPS.
- **Примеры:** PostgreSQL, MySQL, SQL Server, Oracle.
- **Плюсы:** зрелые, понятные, быстрые при вертикальном масштабировании, богатая экосистема.
- **Минусы:** сложности с мульти-региональной строгой консистентностью; горизонтальное масштабирование требует внешних решений (Citus, ProxySQL).

### ✅ Распределённые реляционные (NewSQL / Distributed SQL)
- **Подходят для:** географически распределённая сеть (филиалы в разных регионах), требования к горизонтальному масштабированию и строгой глобальной консистентности.
- **Примеры:** CockroachDB, YugabyteDB, Google Cloud Spanner, TiDB.
- **Плюсы:** ACID-транзакции с автоматическим шардингом, мульти-региональная консистентность «из коробки», geo-partitioning для локализации данных.
- **Минусы:** повышенная латентность при кросс-региональных операциях, сложнее в администрировании, требуют аккуратного дизайна ключей.

### ⚠️ Облачные managed РСУБД
- **Подходят для:** региональная высокая доступность без необходимости строгой глобальной консистентности.
- **Примеры:** Amazon Aurora, Google AlloyDB, Azure SQL Database.
- **Плюсы:** простота эксплуатации, автоматическое резервирование и failover в пределах региона.
- **Минусы:** межрегиональная репликация асинхронная (eventual consistency), vendor lock-in.

### ❌ NoSQL
- **Не подходят:** eventual consistency и слабые транзакционные гарантии не соответствуют требованиям кейса (остатки, бонусы — критичная целостность).
- **Примеры:** Cassandra, DynamoDB, MongoDB.
- **Когда уместны:** для вспомогательных данных (каталоги, логи), но не как «источник правды» для денег и остатков.

## Приведите примеры конкретных СУБД, которые вы бы выбрали

**Сценарий 1: Региональная сеть (до 500 магазинов, один регион)**
- **PostgreSQL** — классическое решение с master-replica, streaming replication, Patroni для автоматического failover.

**Сценарий 2: Крупная географически распределённая сеть (1000+ магазинов, несколько регионов)**
- **YugabyteDB** — распределённая SQL СУБД с PostgreSQL-совместимостью, строгой консистентностью и geo-partitioning.

**Альтернативы при мульти-регионе:**
- **CockroachDB** — если нужна максимальная автоматизация и SERIALIZABLE изоляция по умолчанию.
- **Google Cloud Spanner** — если инфраструктура полностью на GCP и бюджет позволяет managed-решение.

## Обоснуйте ваш выбор: почему именно эта СУБД?

### **YugabyteDB (YSQL)** — основной выбор для крупной распределённой сети

**Почему:**
- **PostgreSQL-совместимость** — низкий порог входа для разработчиков, можно использовать знакомые инструменты (PgBouncer, pgAdmin, dbt), большая часть PL/pgSQL-кода портируется без изменений.
- **Строгая мульти-региональная консистентность** — Raft-консенсус обеспечивает ACID между регионами; списание бонусов в Москве сразу видно в Санкт-Петербурге.
- **Geo-partitioning** — таблицы можно партиционировать по региону/городу, чтобы данные магазина хранились физически близко к кассам → низкие задержки.
- **Пессимистичные блокировки** — поддерживает `SELECT FOR UPDATE` и row-level locks, что упрощает работу с «горячими» строками (остатки популярных товаров) по сравнению с оптимистичными моделями.
- **Open-source** — нет vendor lock-in, можно разворачивать в любом облаке или on-premise; активное сообщество.

---

### **PostgreSQL** — для региональных сетей средних масштабов

**Когда подходит:**  
Сеть до 500 магазинов в одном городе/регионе, централизованная инфраструктура, нагрузка до 20k транзакций в секунду.

**Почему:**
- Зрелая СУБД с полной поддержкой ACID, надёжными механизмами транзакций и constraints.
- Широкая экосистема инструментов (PgBouncer, Patroni, репликация) и активное сообщество.
- Отлично справляется с OLTP-нагрузкой средней интенсивности, нет лицензионных затрат.

**Почему не для мульти-региона:**  
Между регионами нет строгой консистентности «из коробки»; асинхронная репликация создаёт риск потери данных при сбое primary. Для мульти-региона придётся строить собственный шардинг или переходить на Citus/YugabyteDB.

## Какие риски или проблемы могут возникнуть при эксплуатации выбранной СУБД?

### **YugabyteDB**

**Технические риски:**
- **Неполная совместимость с PostgreSQL** — часть расширений (PostGIS, pg_cron, некоторые триггеры) недоступна; нужна проверка миграции.
- **Ретраи транзакций при конфликтах** — оптимистичная модель может приводить к откатам; требуются идемпотентные операции и логика повторных попыток на уровне приложения.
- **«Горячие» ключи/диапазоны** — если множество касс одновременно обновляют остатки одного товара, может возникнуть bottleneck на tablet leader. Решение: использовать `SELECT FOR UPDATE` или эскроу-счётчики, корректный дизайн Primary Key.
- **Кросс-региональная латентность** — операции между регионами будут медленнее из-за кворума между узлами. Минимизировать через geo-partitioning и локализацию транзакций.
- **Размещение tablet leaders** — неправильная конфигурация может привести к тому, что лидер таблетки окажется в другом регионе → скачки задержки. Требуется настройка placement policies.

**Операционные риски:**
- **LSM-компакции** — write-amplification в RocksDB может вызывать всплески IO; нужен запас IOPS и мониторинг уровней компакции.
- **Бэкапы и PITR** — распределённые бэкапы сложнее; требуются регулярные тесты восстановления и автоматизация.
- **Апгрейды** — rolling upgrades требуют аккуратности; поузловое обновление с проверкой метрик после каждого узла.
- **Стоимость инфраструктуры** — 3× репликация + мульти-регион = больше узлов, больше сети, выше TCO.
- **Квалификация персонала** — нужны навыки работы с распределёнными системами, пониманием Raft, tablet rebalancing, troubleshooting cross-region latency.

---

### **PostgreSQL**

**Технические риски:**
- **Вертикальный потолок масштабирования** — при росте нагрузки упрёмся в лимиты CPU/RAM одного узла; переход на шардинг (Citus) или распределённую СУБД потребует рефакторинга.
- **Конкуренция за горячие строки** — обновление остатков популярных товаров может вызывать блокировки и дедлоки; требуется оптимизация (короткие транзакции, `SELECT FOR UPDATE SKIP LOCKED`).
- **VACUUM и MVCC-разбухание** — высокая нагрузка на запись создаёт «мёртвые» версии строк; без регулярного `VACUUM` производительность деградирует.
- **Репликационная задержка** — асинхронная репликация может привести к потере последних транзакций при сбое primary; синхронная репликация увеличивает латентность.
- **Отсутствие встроенного failover** — требуется внешний инструмент (Patroni, repmgr, pg_auto_failover), что усложняет стек и добавляет точки отказа (etcd, Consul).

**Операционные риски:**
- **Отсутствие изоляции ресурсов** — BI-запросы/отчёты могут мешать OLTP-операциям касс; рекомендуется выделять отдельный read-replica для аналитики.
- **Сложность масштабирования записи** — добавление read-replica не помогает с write-нагрузкой; для горизонтального масштабирования записи нужен Citus или миграция на NewSQL.

---

### **Общие риски**

- **Неверная модель данных** — денормализация ради скорости может нарушить целостность; избыточная нормализация замедлит JOIN-ы.
- **Недостаточное тестирование нагрузки** — синтетические тесты не всегда отражают реальное поведение тысяч касс; требуется chaos engineering и нагрузочное тестирование.
- **Мониторинг и алерты** — без метрик (latency p99, TPS, блокировки, ретраи, replica lag) невозможно вовремя обнаружить деградацию; обязательны Prometheus + Grafana + alerting.
- **Disaster Recovery** — отсутствие DR-плана и регулярных тестов восстановления может привести к потере данных при катастрофическом сбое.

---

## Примечание

При подготовке ответа использовались модели **Claude Sonnet 4.5** и **GPT-5** для структурирования материала, анализа классов СУБД и оценки рисков. Финальные рекомендации основаны на документации СУБД и практическом опыте работы. Промты включали:
- Сравнение типов СУБД (реляционные, распределённые, NewSQL, NoSQL, managed) в контексте кейса.
- Анализ конкретных решений (YugabyteDB, CockroachDB, PostgreSQL) с плюсами/минусами.
- Генерация списка рисков для выбранной СУБД.
